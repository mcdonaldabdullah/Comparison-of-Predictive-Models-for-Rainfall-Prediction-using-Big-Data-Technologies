{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "from skimage.util.shape import view_as_windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying a Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (1000, 3600, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#this reads in an image from the dataset and then displays it\n",
    "correct_orientation_images_path = Path(r'D:\\BSc (Hons) Computer Sciences\\2020\\Big Data Engineering\\Group Project\\Preprocessing\\correct orientation')\n",
    "\n",
    "for img_path in correct_orientation_images_path.glob('*.png'):          \n",
    "    img = image.load_img(img_path)\n",
    "    img = image.img_to_array(img)\n",
    "    print(\"Image shape: {}\".format(img.shape))\n",
    "    break\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cropping Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function crops the area of Bangladesh from the images in the dataset\n",
    "def crop_images(dataset_path, new_dataset_path):\n",
    "    for img_path in dataset_path.glob('*.png'):    \n",
    "        try:\n",
    "            img_name = str(img_path).split(\"\\\\\")[-1]\n",
    "            image = Image.open(img_path)\n",
    "            image2 = image.crop((2650, 175, 2770, 300))\n",
    "            image2 = image2.resize((40, 40))\n",
    "            image2.save(new_dataset_path / img_name)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "        \n",
    "#set the path where the cropped images should be stored\n",
    "cropped_images_path = Path(r'D:\\BSc (Hons) Computer Sciences\\2020\\Big Data Engineering\\Group Project\\Preprocessing\\bangladesh 2')\n",
    "#crop_images(correct_orientation_images_path, cropped_images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this takes the cropped images and separates them into training and testing images\n",
    "from keras.preprocessing import image\n",
    "\n",
    "train = []\n",
    "test = []\n",
    "counter = 0\n",
    "\n",
    "for img_path in cropped_images_path.glob('*.png'):\n",
    "    if counter < 100:\n",
    "        img = image.load_img(img_path, target_size=(40, 40), grayscale=True)\n",
    "        img = image.img_to_array(img)\n",
    "        img = np.array(img).reshape(40, 40)\n",
    "        train.append(img)\n",
    "    elif counter >= 150:\n",
    "        continue\n",
    "    else:\n",
    "        img = image.load_img(img_path, target_size=(40, 40), grayscale=True)\n",
    "        img = image.img_to_array(img)\n",
    "        img = np.array(img).reshape(40, 40)\n",
    "        test.append(img)\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.array(train)\n",
    "test = np.array(test)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Sequences of Pixels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this adds some weighting to the pixels values in a neighborhood around a specific pixel\n",
    "def pixel_weighting(L):\n",
    "    result=[]\n",
    "    for r in range(L.shape[0]):\n",
    "        for c in range(L.shape[1]):\n",
    "            array = np.array(L[r][c]).flatten()\n",
    "            pixel_of_interest_1 = array[4]\n",
    "            pixel_of_interest_2 = array[4]\n",
    "            for index in range(array.shape[0]):\n",
    "                if index==4:\n",
    "                    continue\n",
    "                elif array[index] > pixel_of_interest_1:\n",
    "                    pixel_of_interest_2 = pixel_of_interest_2 + array[index]*0.00\n",
    "                elif array[index] < pixel_of_interest_1:\n",
    "                    pixel_of_interest_2 = pixel_of_interest_2 - array[index]*0.00\n",
    "            if pixel_of_interest_2 < 0:\n",
    "                pixel_of_interest_2 = 0\n",
    "            result.append(pixel_of_interest_2)\n",
    "            \n",
    "    return np.array(result).reshape(L.shape[0], L.shape[1])\n",
    "\n",
    "#creates sequence of images\n",
    "def gettingSequence(X, sequence_length, months_ahead, neighborhood_size=(3, 3)):\n",
    "    \n",
    "    Y=[]\n",
    "    dataX = []\n",
    "    \n",
    "    for num in range(X.shape[0]-(sequence_length + months_ahead)+1):\n",
    "        sequence=[]\n",
    "        for i in range(sequence_length+months_ahead):\n",
    "            if (i < sequence_length):\n",
    "                #just taking the average of the neighborhood pixels in the meantime\n",
    "                A = np.pad(X[i+num], 1, mode='constant')\n",
    "                neighborhoods = view_as_windows(A, neighborhood_size)\n",
    "                \n",
    "                B = pixel_weighting(neighborhoods).flatten()\n",
    "                \n",
    "                \n",
    "                sequence.append(B)\n",
    "                \n",
    "            elif (i == (sequence_length+months_ahead-1)):\n",
    "                Y.append(X[i+num].flatten())\n",
    "                \n",
    "            if (i == sequence_length-1):        \n",
    "                dataX.append(sequence)\n",
    "                \n",
    "    return dataX, Y\n",
    "\n",
    "#this creates a sequence of pixels\n",
    "def create_training_dataset(X_seq, GT):\n",
    "    X1 = []\n",
    "    Y = []\n",
    "    for sample_no in range(X_seq.shape[0]):\n",
    "        x = X_seq[sample_no].T #T is just the transpose function on matrices\n",
    "        y = GT[sample_no]\n",
    "        for i in range(x.shape[0]):\n",
    "            X1.append(x[i])\n",
    "            Y.append(y[i])\n",
    "    return X1, np.array(Y).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_big_data_files(sequence_length, months_ahead):\n",
    "    #getting sequences and ground truth for those sequences using a specified sequence length and the number of months ahead\n",
    "    X_sequences_train, ground_truth_train = gettingSequence(train, sequence_length, months_ahead)\n",
    "    X_sequences_test, ground_truth_test = gettingSequence(test, sequence_length, months_ahead)\n",
    "    #converting to numpy arrays\n",
    "    X_sequences_train = np.array(X_sequences_train)\n",
    "    ground_truth_train = np.array(ground_truth_train)\n",
    "    X_sequences_test = np.array(X_sequences_test)\n",
    "    ground_truth_test = np.array(ground_truth_test)\n",
    "    \n",
    "    num_of_images = ground_truth_test.shape[0]\n",
    "    #here we create sequences of pixels\n",
    "    train_X, train_Y = create_training_dataset(X_sequences_train, ground_truth_train)\n",
    "    test_X, test_Y = create_training_dataset(X_sequences_test, ground_truth_test)\n",
    "    #converting to numpy arrays\n",
    "    train_X = np.array(train_X)\n",
    "    train_Y = np.array(train_Y)\n",
    "    test_X = np.array(test_X)\n",
    "    test_Y = np.array(test_Y)\n",
    "    \n",
    "    #all these statements does is that it creates a pandas dataframe using the sequence of pixels we created above\n",
    "    if sequence_length == 4:\n",
    "        train_df = pd.DataFrame(train_X, columns=[\"M1\", \"M2\", \"M3\", \"M4\"])\n",
    "        test_df = pd.DataFrame(test_X, columns=[\"M1\", \"M2\", \"M3\", \"M4\"])\n",
    "    elif sequence_length == 8:\n",
    "        train_df = pd.DataFrame(train_X, columns=[\"M1\", \"M2\", \"M3\", \"M4\", \"M5\", \"M6\", \"M7\", \"M8\"])\n",
    "        test_df = pd.DataFrame(test_X, columns=[\"M1\", \"M2\", \"M3\", \"M4\", \"M5\", \"M6\", \"M7\", \"M8\"])\n",
    "\n",
    "    elif sequence_length == 12:\n",
    "        train_df = pd.DataFrame(train_X, columns=[\"M1\", \"M2\", \"M3\", \"M4\", \"M5\", \"M6\", \"M7\", \"M8\", \"M9\", \"M10\", \"M11\", \"M12\"])\n",
    "        test_df = pd.DataFrame(test_X, columns=[\"M1\", \"M2\", \"M3\", \"M4\", \"M5\", \"M6\", \"M7\", \"M8\", \"M9\", \"M10\", \"M11\", \"M12\"])\n",
    "\n",
    "    train_df['GT'] = train_Y\n",
    "    test_df['GT'] = test_Y\n",
    "    #setting the name of the files \n",
    "    train_file_name = r\"Preprocessed Data\\train_sequence_length_\"+str(sequence_length)+\"_month_ahead_\"+str(months_ahead)+\".txt\"\n",
    "    test_file_name = r\"Preprocessed Data\\test_sequence_length_\"+str(sequence_length)+\"_month_ahead_\"+str(months_ahead)+\".txt\"\n",
    "    #storing the pandas dataframes which hold the sequence of pixels to a text file which will then be stored in Hadoop HDFS\n",
    "    train_df.to_csv(train_file_name)\n",
    "    test_df.to_csv(test_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creating the files used to the 1 month ahead predictions\n",
    "create_big_data_files(4, 1)\n",
    "create_big_data_files(8, 1)\n",
    "create_big_data_files(12, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the files used to the 2 months ahead predictions\n",
    "create_big_data_files(4, 2)\n",
    "create_big_data_files(8, 2)\n",
    "create_big_data_files(12, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the files used to the 3 months ahead predictions\n",
    "create_big_data_files(4, 3)\n",
    "create_big_data_files(8, 3)\n",
    "create_big_data_files(12, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Flatten Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we read in the cropped images again so that we can flatten each image. \n",
    "#These flattened images will be used to do some analysis using Spark\n",
    "from keras.preprocessing import image\n",
    "\n",
    "images_path = Path(r'D:\\BSc (Hons) Computer Sciences\\2020\\Big Data Engineering\\Group Project\\Preprocessing\\Bangladesh')\n",
    "\n",
    "images = []\n",
    "counter = 0\n",
    "\n",
    "for img_path in images_path.glob('*.png'):\n",
    "    img = image.load_img(img_path, target_size=(40, 40), grayscale=True)\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.array(img).reshape(40, 40)\n",
    "    images.append(img)\n",
    "\n",
    "#images array\n",
    "images = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this flattens each image array\n",
    "def flatten_images(array):\n",
    "    result = []\n",
    "    for i in range(array.shape[0]):\n",
    "        result.append(list(array[i].flatten()))\n",
    "    return np.array(result)\n",
    "\n",
    "\n",
    "images_flatten = flatten_images(images)\n",
    "#convert flattened image array to pandas dataframe so that we can store it in a text file\n",
    "images_df = pd.DataFrame(images_flatten)\n",
    "#storing the pandas dataframe in a text file\n",
    "images_df.to_csv(r'Preprocessed Data\\images_flatten.txt', sep=',', encoding='utf-8', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
